// This file is computer-generated by onnx2c 
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 2.6.0
// ONNX IR version: 18
// Model documentation: 
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
#include <stdlib.h>

#include "network.h"

#define MAX(X,Y) ( X > Y ? X : Y)
#define MIN(X,Y) ( X < Y ? X : Y)
#define CLIP(X,L) ( MAX(MIN(X,L), -L) )

#if __STDC_VERSION__ < 199901L
#define FUNC_PREFIX
#else
#define FUNC_PREFIX static inline
#endif

static const float tensor_onnx__Conv_103[8][8][1][1] = 
{
  {
    {
      {-0.10472196340560913086f}
    },
    {
      {0.23810717463493347168f}
    },
    {
      {-0.28342065215110778809f}
    },
    {
      {0.25510907173156738281f}
    },
    {
      {0.03724536299705505371f}
    },
    {
      {-0.34634763002395629883f}
    },
    {
      {-0.04507903009653091431f}
    },
    {
      {-0.02015043422579765320f}
    }
  },
  {
    {
      {-0.16501909494400024414f}
    },
    {
      {0.29716998338699340820f}
    },
    {
      {0.10045882314443588257f}
    },
    {
      {-0.19191357493400573730f}
    },
    {
      {-0.11540916562080383301f}
    },
    {
      {0.30931973457336425781f}
    },
    {
      {0.24656473100185394287f}
    },
    {
      {0.29571408033370971680f}
    }
  },
  {
    {
      {-0.09709616005420684814f}
    },
    {
      {0.30198651552200317383f}
    },
    {
      {0.12818314135074615479f}
    },
    {
      {0.06665182858705520630f}
    },
    {
      {-0.14216759800910949707f}
    },
    {
      {-0.13810408115386962891f}
    },
    {
      {0.07490216195583343506f}
    },
    {
      {0.05339620634913444519f}
    }
  },
  {
    {
      {-0.00295591214671730995f}
    },
    {
      {-0.16035121679306030273f}
    },
    {
      {0.33538216352462768555f}
    },
    {
      {0.15048186480998992920f}
    },
    {
      {-0.02140627615153789520f}
    },
    {
      {0.16037495434284210205f}
    },
    {
      {0.03718441724777221680f}
    },
    {
      {-0.06497329473495483398f}
    }
  },
  {
    {
      {-0.21687608957290649414f}
    },
    {
      {-0.04327191039919853210f}
    },
    {
      {0.14648199081420898438f}
    },
    {
      {-0.10613813251256942749f}
    },
    {
      {-0.01648325473070144653f}
    },
    {
      {0.12495651841163635254f}
    },
    {
      {0.30822786688804626465f}
    },
    {
      {0.13182675838470458984f}
    }
  },
  {
    {
      {0.04767433553934097290f}
    },
    {
      {0.22076834738254547119f}
    },
    {
      {-0.00816135853528976440f}
    },
    {
      {0.02197466604411602020f}
    },
    {
      {0.08967363089323043823f}
    },
    {
      {-0.22025498747825622559f}
    },
    {
      {-0.00120450870599597692f}
    },
    {
      {-0.09093435853719711304f}
    }
  },
  {
    {
      {0.19909678399562835693f}
    },
    {
      {-0.05092873424291610718f}
    },
    {
      {-0.26813754439353942871f}
    },
    {
      {-0.08754071593284606934f}
    },
    {
      {0.23695023357868194580f}
    },
    {
      {-0.15044493973255157471f}
    },
    {
      {0.35156628489494323730f}
    },
    {
      {-0.33392307162284851074f}
    }
  },
  {
    {
      {0.21742978692054748535f}
    },
    {
      {-0.14325430989265441895f}
    },
    {
      {0.28127813339233398438f}
    },
    {
      {-0.12447831779718399048f}
    },
    {
      {0.30069103837013244629f}
    },
    {
      {0.28306841850280761719f}
    },
    {
      {-0.22593632340431213379f}
    },
    {
      {0.21357710659503936768f}
    }
  }
};
static const float tensor_onnx__Conv_104[8] = 
{0.00000000000000000000f, 0.00000000000000000000f, 0.00000000000000000000f, 0.00000000000000000000f, 0.00000000000000000000f, 0.00000000000000000000f, 0.00000000000000000000f, 0.00000000000000000000f};
static const float tensor_onnx__Conv_106[8][4][1] = 
{
  {
    {-0.15168811380863189697f},
    {-0.11252048611640930176f},
    {-0.44500967860221862793f},
    {-0.14322572946548461914f}
  },
  {
    {-0.10970513522624969482f},
    {0.20300108194351196289f},
    {-0.28337895870208740234f},
    {0.17743605375289916992f}
  },
  {
    {-0.16897915303707122803f},
    {-0.08089186251163482666f},
    {-0.27825650572776794434f},
    {-0.03796498849987983704f}
  },
  {
    {0.17748486995697021484f},
    {0.47831124067306518555f},
    {0.43942427635192871094f},
    {0.20460186898708343506f}
  },
  {
    {0.00662859948351979256f},
    {0.19944031536579132080f},
    {0.07408671081066131592f},
    {0.00036197720328345895f}
  },
  {
    {-0.44342899322509765625f},
    {0.48166498541831970215f},
    {0.08946487307548522949f},
    {0.31485894322395324707f}
  },
  {
    {0.13552060723304748535f},
    {0.42352434992790222168f},
    {0.12820191681385040283f},
    {0.14458350837230682373f}
  },
  {
    {-0.43231466412544250488f},
    {0.13694539666175842285f},
    {-0.07879676669836044312f},
    {-0.29660373926162719727f}
  }
};
static const int64_t tensor__Where_output_0_static[4] = 
{8, 4, 10, 3};
static const float tensor__Constant_output_0 = 
-2.00000000000000000000f;
static const float tensor__Constant_1_output_0 = 
2.00000000000000000000f;
static const int64_t tensor_onnx__ReduceSum_22[1] = 
{1};
static const int64_t tensor__Constant_2_output_0[1] = 
{4};
static const int64_t tensor__Constant_3_output_0[1] = 
{2};
static const int64_t tensor__Constant_4_output_0[1] = 
{1};
static const int64_t tensor__Constant_5_output_0[1] = 
{9223372036854775807};
static const int64_t tensor__Constant_6_output_0[1] = 
{1};
static const int64_t tensor__Constant_7_output_0[8][1][1] = 
{
  {
    {0}
  },
  {
    {10}
  },
  {
    {20}
  },
  {
    {30}
  },
  {
    {40}
  },
  {
    {50}
  },
  {
    {60}
  },
  {
    {70}
  }
};
static const int64_t tensor__Constant_8_output_0[1] = 
{-1};
static const int64_t tensor__Constant_9_output_0[2] = 
{4, -1};
static const int64_t tensor__Constant_10_output_0[4] = 
{4, 8, 10, 3};
static const int64_t tensor__Constant_11_output_0[1] = 
{-1};
static const int64_t tensor__Constant_12_output_0[4] = 
{8, 4, 10, 3};
static const int64_t tensor__Constant_13_output_0[1] = 
{4};
static const int64_t tensor__Constant_14_output_0 = 
-1;
static const int64_t tensor__Constant_15_output_0[1] = 
{-1};
union tensor_union_0 {
float tensor_onnx__Conv_107[8];
float tensor__Add_1_output_0[8][8][10];
};
static union tensor_union_0 tu0;

union tensor_union_1 {
float tensor__Transpose_output_0[8][10][3];
float tensor__Mul_output_0[8][10][10];
float tensor__Transpose_1_output_0[8][10][1];
float tensor__TopK_output_0[8][10][4];
int64_t tensor__Slice_output_0[8][10][3];
int64_t tensor__Reshape_output_0[240];
float tensor__Reshape_2_output_0[4][8][10][3];
float tensor__Unsqueeze_output_0[8][4][10][1];
float tensor__Sub_2_output_0[8][4][10][3];
float tensor__convs_0_Conv_output_0[8][8][10][3];
float tensor__ReduceMean_output_0[8][8][10];
};
static union tensor_union_1 tu1;

union tensor_union_2 {
float tensor__MatMul_output_0[8][10][10];
float tensor__Pow_output_0[8][3][10];
float tensor__Neg_output_0[8][1][10];
float tensor__Sub_1_output_0[8][10][10];
int64_t tensor__Add_output_0[8][10][3];
float tensor__Transpose_2_output_0[4][8][10];
float tensor__Gather_output_0[4][240];
float tensor__Transpose_3_output_0[8][4][10][3];
float tensor__Concat_output_0[8][8][10][3];
float tensor__acts_0_Relu_output_0[8][8][10][3];
float tensor__sc_Conv_output_0[8][8][10];
};
static union tensor_union_2 tu2;

union tensor_union_3 {
float tensor__ReduceSum_output_0[8][1][10];
int64_t tensor__TopK_output_1[8][10][4];
float tensor__Reshape_1_output_0[4][80];
int64_t tensor__ConstantOfShape_output_0[4];
bool tensor__Equal_output_0[4];
float tensor__Expand_output_0[8][4][10][3];
};
static union tensor_union_3 tu3;

union tensor_union_4 {
float tensor__Sub_output_0[8][10][10];
int64_t tensor__Mul_1_output_0[4];
};
static union tensor_union_4 tu4;


/*
 * Operand:           Identity
 * Name in ONNX file: Identity_17
 */
FUNC_PREFIX void node_Identity_17( const float input[8], float output[8] )
{
	/* Identity */
	const float* input_ptr = (const float*) input;
	float* output_ptr = (float*) output;
	for (unsigned i = 0; i < 8; i++)
		output_ptr[i] = input_ptr[i];
}

/*
 * Operand:           Transpose
 * Name in ONNX file: /Transpose
 */
FUNC_PREFIX void node__Transpose( const float input[8][3][10], float output[8][10][3] )
{
	/* Transpose
	 * perm = 0 2 1 
	 */
	for( uint32_t i0=0; i0<8; i0++ ) {
	for( uint32_t i1=0; i1<3; i1++ ) {
	for( uint32_t i2=0; i2<10; i2++ ) {
		output[i0][i2][i1] = input[i0][i1][i2];
	}
	}
	}
}

/*
 * Operand:           MatMul
 * Name in ONNX file: /MatMul
 */
FUNC_PREFIX void node__MatMul( const float A[8][10][3], const float B[8][3][10], float Y[8][10][10] )
{
	/* MatMul */
	for (unsigned i0=0; i0<8; i0++)
	{
		for (unsigned i = 0; i < 10; i++)
		for (unsigned j = 0; j < 10; j++)
		{
			Y[i0][i][j] = 0;
			for (unsigned k = 0; k < 3; k++)
				Y[i0][i][j] += A[i0][i][k] * B[i0][k][j];
		}
	}
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant
 */
FUNC_PREFIX void node__Constant( const float *output )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Mul
 * Name in ONNX file: /Mul
 */
FUNC_PREFIX void node__Mul( const float A[8][10][10], const float *B, float C[8][10][10] )
{
	/* Mul
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<8; i0++)
	for (unsigned i1=0; i1<10; i1++)
	for (unsigned i2=0; i2<10; i2++)
	{
		C[i0][i1][i2] = A[i0][i1][i2]**B;;
	}
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_1
 */
FUNC_PREFIX void node__Constant_1( const float *output )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Pow
 * Name in ONNX file: /Pow
 */
FUNC_PREFIX void node__Pow( const float A[8][3][10], const float *B, float C[8][3][10] )
{
	/* Pow
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<8; i0++)
	for (unsigned i1=0; i1<3; i1++)
	for (unsigned i2=0; i2<10; i2++)
	{
		C[i0][i1][i2] = powf(A[i0][i1][i2],*B);;
	}
}

/*
 * Operand:           Constant
 * Name in ONNX file: Constant_24
 */
FUNC_PREFIX void node_Constant_24( const int64_t output[1] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           ReduceSum
 * Name in ONNX file: /ReduceSum
 */
FUNC_PREFIX void node__ReduceSum( const float x[8][3][10], const int64_t axes[1], float y[8][1][10] )
{
	/* ReduceSum */
	/* keepdims: 1 */
	/* axes: (	1	) */
	for (unsigned i0 = 0; i0<8; i0++) {
		for (unsigned i1 = 0; i1<1; i1++) {
			for (unsigned i2 = 0; i2<10; i2++) {
				y[i0][i1][i2] = 0.0;
			}
		}
	}
	for (unsigned i0 = 0; i0<8; i0++) {
		for (unsigned i1 = 0; i1<3; i1++) {
			for (unsigned i2 = 0; i2<10; i2++) {
				y[i0][0][i2]+=x[i0][i1][i2];
			}
		}
	}
}

/*
 * Operand:           Neg
 * Name in ONNX file: /Neg
 */
FUNC_PREFIX void node__Neg( const float X[8][1][10], float Y[8][1][10] )
{
	/* Neg
	   Implemented with Elementwise template.
	   alpha = 0.00000000000000000000
	   beta = 0.00000000000000000000
	*/
	for (unsigned i0=0; i0<8; i0++) {
	for (unsigned i1=0; i1<1; i1++) {
	for (unsigned i2=0; i2<10; i2++) {
		Y[i0][i1][i2] =  -X[i0][i1][i2];
	}
	}
	}
}

/*
 * Operand:           Sub
 * Name in ONNX file: /Sub
 */
FUNC_PREFIX void node__Sub( const float A[8][1][10], const float B[8][10][10], float C[8][10][10] )
{
	/* Sub
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<8; i0++)
	for (unsigned i1=0; i1<10; i1++)
	for (unsigned i2=0; i2<10; i2++)
	{
		C[i0][i1][i2] = A[i0][0][i2]-B[i0][i1][i2];;
	}
}

/*
 * Operand:           Transpose
 * Name in ONNX file: /Transpose_1
 */
FUNC_PREFIX void node__Transpose_1( const float input[8][1][10], float output[8][10][1] )
{
	/* Transpose
	 * perm = 0 2 1 
	 */
	for( uint32_t i0=0; i0<8; i0++ ) {
	for( uint32_t i1=0; i1<1; i1++ ) {
	for( uint32_t i2=0; i2<10; i2++ ) {
		output[i0][i2][i1] = input[i0][i1][i2];
	}
	}
	}
}

/*
 * Operand:           Sub
 * Name in ONNX file: /Sub_1
 */
FUNC_PREFIX void node__Sub_1( const float A[8][10][10], const float B[8][10][1], float C[8][10][10] )
{
	/* Sub
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<8; i0++)
	for (unsigned i1=0; i1<10; i1++)
	for (unsigned i2=0; i2<10; i2++)
	{
		C[i0][i1][i2] = A[i0][i1][i2]-B[i0][i1][0];;
	}
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_2
 */
FUNC_PREFIX void node__Constant_2( const int64_t output[1] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           TopK
 * Name in ONNX file: /TopK
 */
FUNC_PREFIX void node__TopK( const float X[8][10][10], const int64_t K[1], float Values[8][10][4], int64_t Indices[8][10][4] )
{
	/* TopK with largest=1, sorted=1, other options not currently supported */
	for (int i0 = 0; i0 < 8; i0++) {
		for (int i1 = 0; i1 < 10; i1++) {
			for (int k = 0; k < 4; k++) {
				Values[i0][i1][k] = -1e10;
				Indices[i0][i1][k] = -1;
			}
			for (int k = 0; k < 10; k++) {
				for (int d = 0; d < 4; d++) {
					if (X[i0][i1][k] > Values[i0][i1][d]) {
						for (int s = 3; s > d; s--) {
							Values[i0][i1][s] = Values[i0][i1][s - 1];
							Indices[i0][i1][s] = Indices[i0][i1][s - 1];
						}
						Values[i0][i1][d] = X[i0][i1][k];
						Indices[i0][i1][d] = k;
						break;
					}
				}
			}
		}
	}
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_3
 */
FUNC_PREFIX void node__Constant_3( const int64_t output[1] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_4
 */
FUNC_PREFIX void node__Constant_4( const int64_t output[1] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_5
 */
FUNC_PREFIX void node__Constant_5( const int64_t output[1] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_6
 */
FUNC_PREFIX void node__Constant_6( const int64_t output[1] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Slice
 * Name in ONNX file: /Slice
 */
FUNC_PREFIX void node__Slice( const int64_t data[8][10][4], const int64_t starts[1], const int64_t ends[1], const int64_t axes[1], const int64_t steps[1], int64_t output[8][10][3] )
{
	for (unsigned i0=0, o0=0; o0<8; i0+=1, o0++) {
	for (unsigned i1=0, o1=0; o1<10; i1+=1, o1++) {
	for (unsigned i2=1, o2=0; o2<3; i2+=1, o2++) {
		output[o0][o1][o2] = data[i0][i1][i2];
	}
	}
	}
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_7
 */
FUNC_PREFIX void node__Constant_7( const int64_t output[8][1][1] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Add
 * Name in ONNX file: /Add
 */
FUNC_PREFIX void node__Add( const int64_t A[8][10][3], const int64_t B[8][1][1], int64_t C[8][10][3] )
{
	/* Add
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<8; i0++)
	for (unsigned i1=0; i1<10; i1++)
	for (unsigned i2=0; i2<3; i2++)
	{
		C[i0][i1][i2] = A[i0][i1][i2]+B[i0][0][0];;
	}
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_8
 */
FUNC_PREFIX void node__Constant_8( const int64_t output[1] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /Reshape
 */
FUNC_PREFIX void node__Reshape( const int64_t data[8][10][3], const int64_t shape[1], int64_t reshaped[240] )
{
	/*Reshape*/
	int64_t *data_ptr = (int64_t*)data;
	int64_t *reshaped_ptr = (int64_t*)reshaped;
	uint32_t i;
	for( i=0; i<240; i++ )
		reshaped_ptr[i] = data_ptr[i];

}

/*
 * Operand:           Transpose
 * Name in ONNX file: /Transpose_2
 */
FUNC_PREFIX void node__Transpose_2( const float input[8][4][10], float output[4][8][10] )
{
	/* Transpose
	 * perm = 1 0 2 
	 */
	for( uint32_t i0=0; i0<8; i0++ ) {
	for( uint32_t i1=0; i1<4; i1++ ) {
	for( uint32_t i2=0; i2<10; i2++ ) {
		output[i1][i0][i2] = input[i0][i1][i2];
	}
	}
	}
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_9
 */
FUNC_PREFIX void node__Constant_9( const int64_t output[2] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /Reshape_1
 */
FUNC_PREFIX void node__Reshape_1( const float data[4][8][10], const int64_t shape[2], float reshaped[4][80] )
{
	/*Reshape*/
	float *data_ptr = (float*)data;
	float *reshaped_ptr = (float*)reshaped;
	uint32_t i;
	for( i=0; i<320; i++ )
		reshaped_ptr[i] = data_ptr[i];

}

/*
 * Operand:           Gather
 * Name in ONNX file: /Gather
 */
FUNC_PREFIX void node__Gather( const float X[4][80], const int64_t indices[240], float Y[4][240] )
{
	/* Gather
	   axis = 1
	 */
	for (unsigned i0=0; i0<4; i0++)
	for (unsigned i1=0; i1<240; i1++)
	{
		int32_t idx = indices[i1];
		idx = idx < 0 ? 80+idx : idx;
		Y[i0][i1] = X[i0][idx];
	}
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_10
 */
FUNC_PREFIX void node__Constant_10( const int64_t output[4] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /Reshape_2
 */
FUNC_PREFIX void node__Reshape_2( const float data[4][240], const int64_t shape[4], float reshaped[4][8][10][3] )
{
	/*Reshape*/
	float *data_ptr = (float*)data;
	float *reshaped_ptr = (float*)reshaped;
	uint32_t i;
	for( i=0; i<960; i++ )
		reshaped_ptr[i] = data_ptr[i];

}

/*
 * Operand:           Transpose
 * Name in ONNX file: /Transpose_3
 */
FUNC_PREFIX void node__Transpose_3( const float input[4][8][10][3], float output[8][4][10][3] )
{
	/* Transpose
	 * perm = 1 0 2 3 
	 */
	for( uint32_t i0=0; i0<4; i0++ ) {
	for( uint32_t i1=0; i1<8; i1++ ) {
	for( uint32_t i2=0; i2<10; i2++ ) {
	for( uint32_t i3=0; i3<3; i3++ ) {
		output[i1][i0][i2][i3] = input[i0][i1][i2][i3];
	}
	}
	}
	}
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_11
 */
FUNC_PREFIX void node__Constant_11( const int64_t output[1] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Unsqueeze
 * Name in ONNX file: /Unsqueeze
 */
FUNC_PREFIX void node__Unsqueeze( const float input[8][4][10], const int64_t axes_tensor[1], float output[8][4][10][1] )
{
	/* Unsqueeze */
	float *data = (float*)input;
	float *expanded= (float*)output;
	for( uint32_t i=0; i<320; i++ )
		expanded[i] = data[i];

}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_12
 */
FUNC_PREFIX void node__Constant_12( const int64_t output[4] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_13
 */
FUNC_PREFIX void node__Constant_13( const int64_t output[1] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           ConstantOfShape
 * Name in ONNX file: /ConstantOfShape
 */
FUNC_PREFIX void node__ConstantOfShape( const int64_t input[1], int64_t output[4] )
{
	/* ConstantOfShape */
	int64_t *dst = (int64_t*)output;
	for( unsigned i=0; i< 4; i++)
		dst[i] = 1;
}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_14
 */
FUNC_PREFIX void node__Constant_14( const int64_t *output )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           Mul
 * Name in ONNX file: /Mul_1
 */
FUNC_PREFIX void node__Mul_1( const int64_t A[4], const int64_t *B, int64_t C[4] )
{
	/* Mul
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<4; i0++)
	{
		C[i0] = A[i0]**B;;
	}
}

/*
 * Operand:           Equal
 * Name in ONNX file: /Equal
 */
FUNC_PREFIX void node__Equal( const int64_t A[4], const int64_t B[4], bool C[4] )
{
	/* Equal
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<4; i0++)
	{
		C[i0] = A[i0]==B[i0];;
	}
}

/*
 * Operand:           Expand
 * Name in ONNX file: /Expand
 */
FUNC_PREFIX void node__Expand( const float input[8][4][10][1], const int64_t shape[4], float output[8][4][10][3] )
{
	/* Expand */
	for( uint32_t o0=0; o0<8; o0++) {
	for( uint32_t o1=0; o1<4; o1++) {
	for( uint32_t o2=0; o2<10; o2++) {
	for( uint32_t o3=0; o3<3; o3++) {
		output[o0][o1][o2][o3] = input[o0][o1][o2][0];
	}
	}
	}
	}
}

/*
 * Operand:           Sub
 * Name in ONNX file: /Sub_2
 */
FUNC_PREFIX void node__Sub_2( const float A[8][4][10][3], const float B[8][4][10][3], float C[8][4][10][3] )
{
	/* Sub
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<8; i0++)
	for (unsigned i1=0; i1<4; i1++)
	for (unsigned i2=0; i2<10; i2++)
	for (unsigned i3=0; i3<3; i3++)
	{
		C[i0][i1][i2][i3] = A[i0][i1][i2][i3]-B[i0][i1][i2][i3];;
	}
}

/*
 * Operand:           Concat
 * Name in ONNX file: /Concat
 */
FUNC_PREFIX void node__Concat( const float input_0[8][4][10][3], const float input_1[8][4][10][3], float output[8][8][10][3] )
{
	/* Concat */
	int64_t outputOffset;
	outputOffset = 0;
	for (int64_t i = 0, j = 0; i < 960; i++) {
		*((float*)output + (outputOffset + i)) = *((float*)input_0 + i);
		if (++j == 120) {
			outputOffset += (120);
			j = 0;
		}
	}
	outputOffset = 120;
	for (int64_t i = 0, j = 0; i < 960; i++) {
		*((float*)output + (outputOffset + i)) = *((float*)input_1 + i);
		if (++j == 120) {
			outputOffset += (120);
			j = 0;
		}
	}
}

/*
 * Operand:           Conv
 * Name in ONNX file: /convs.0/Conv
 */
FUNC_PREFIX void node__convs_0_Conv( const float x[8][8][10][3], const float w[8][8][1][1], const float bias[8], float y[8][8][10][3] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<8; b++ ) {
	for( uint32_t m=0; m<8; m++) {
		for( int32_t o0=0, i0=0; o0<10; o0++, i0+=1) {
		for( int32_t o1=0, i1=0; o1<3; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<8; c++ ) {
			for( uint32_t k0=0; k0<1; k0++ ) {
			for( uint32_t k1=0; k1<1; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=10) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=3) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] * w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /acts.0/Relu
 */
FUNC_PREFIX void node__acts_0_Relu( const float X[8][8][10][3], float Y[8][8][10][3] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	uint32_t i;
	for( i=0; i<1920; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Constant
 * Name in ONNX file: /Constant_15
 */
FUNC_PREFIX void node__Constant_15( const int64_t output[1] )
{
	/* Constant */
	/* The output is generated as a global tensor */
	(void)output;
}

/*
 * Operand:           ReduceMean
 * Name in ONNX file: /ReduceMean
 */
FUNC_PREFIX void node__ReduceMean( const float x[8][8][10][3], const int64_t axes[1], float y[8][8][10] )
{
	/* ReduceMean */
	/* keepdims: 0 */
	/* axes: (	-1	) */
	for (unsigned i0 = 0; i0<8; i0++) {
		for (unsigned i1 = 0; i1<8; i1++) {
			for (unsigned i2 = 0; i2<10; i2++) {
				y[i0][i1][i2] = 0.0;
			}
		}
	}
	for (unsigned i0 = 0; i0<8; i0++) {
		for (unsigned i1 = 0; i1<8; i1++) {
			for (unsigned i2 = 0; i2<10; i2++) {
				for (unsigned i3 = 0; i3<3; i3++) {
					y[i0][i1][i2]+=x[i0][i1][i2][i3];
				}
			}
		}
	}
	/* ReduceMean: Divide by the number of elements (reduced axes) */
	for (unsigned i0 = 0; i0<8; i0++) {
		for (unsigned i1 = 0; i1<8; i1++) {
			for (unsigned i2 = 0; i2<10; i2++) {
				y[i0][i1][i2] /= 3;
			}
		}
	}
}

/*
 * Operand:           Conv
 * Name in ONNX file: /sc/Conv
 */
FUNC_PREFIX void node__sc_Conv( const float x[8][4][10], const float w[8][4][1], const float bias[8], float y[8][8][10] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 
	 * group: 1
	 * kernel_shape: 1 
	 * pads: 0 0 
	 * strides: 1 
	 */
	for( uint32_t b=0; b<8; b++ ) {
	for( uint32_t m=0; m<8; m++) {
		for( int32_t o0=0, i0=0; o0<10; o0++, i0+=1) {
			y[b][m][o0] = bias[m];
			for( int32_t c=0; c<4; c++ ) {
			for( uint32_t k0=0; k0<1; k0++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=10) continue;
				y[b][m][o0] += x[b][c][ii0] * w[m][c][k0];
			} /* k */
			} /* c */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Add
 * Name in ONNX file: /Add_1
 */
FUNC_PREFIX void node__Add_1( const float A[8][8][10], const float B[8][8][10], float C[8][8][10] )
{
	/* Add
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
	for (unsigned i0=0; i0<8; i0++)
	for (unsigned i1=0; i1<8; i1++)
	for (unsigned i2=0; i2<10; i2++)
	{
		C[i0][i1][i2] = A[i0][i1][i2]+B[i0][i1][i2];;
	}
}

/*
 * Operand:           Relu
 * Name in ONNX file: /sc_act/Relu
 */
FUNC_PREFIX void node__sc_act_Relu( const float X[8][8][10], float Y[8][8][10] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	uint32_t i;
	for( i=0; i<640; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}


void entry(const float tensor_pf_points[8][3][10], const float tensor_pf_features[8][4][10], float tensor_output[8][8][10]){
	node_Identity_17( tensor_onnx__Conv_104, tu0.tensor_onnx__Conv_107);
	node__Transpose( tensor_pf_points, tu1.tensor__Transpose_output_0);
	node__MatMul( tu1.tensor__Transpose_output_0, tensor_pf_points, tu2.tensor__MatMul_output_0);
	node__Constant( &tensor__Constant_output_0);
	node__Mul( tu2.tensor__MatMul_output_0, &tensor__Constant_output_0, tu1.tensor__Mul_output_0);
	node__Constant_1( &tensor__Constant_1_output_0);
	node__Pow( tensor_pf_points, &tensor__Constant_1_output_0, tu2.tensor__Pow_output_0);
	node_Constant_24( tensor_onnx__ReduceSum_22);
	node__ReduceSum( tu2.tensor__Pow_output_0, tensor_onnx__ReduceSum_22, tu3.tensor__ReduceSum_output_0);
	node__Neg( tu3.tensor__ReduceSum_output_0, tu2.tensor__Neg_output_0);
	node__Sub( tu2.tensor__Neg_output_0, tu1.tensor__Mul_output_0, tu4.tensor__Sub_output_0);
	node__Transpose_1( tu3.tensor__ReduceSum_output_0, tu1.tensor__Transpose_1_output_0);
	node__Sub_1( tu4.tensor__Sub_output_0, tu1.tensor__Transpose_1_output_0, tu2.tensor__Sub_1_output_0);
	node__Constant_2( tensor__Constant_2_output_0);
	node__TopK( tu2.tensor__Sub_1_output_0, tensor__Constant_2_output_0, tu1.tensor__TopK_output_0, tu3.tensor__TopK_output_1);
	node__Constant_3( tensor__Constant_3_output_0);
	node__Constant_4( tensor__Constant_4_output_0);
	node__Constant_5( tensor__Constant_5_output_0);
	node__Constant_6( tensor__Constant_6_output_0);
	node__Slice( tu3.tensor__TopK_output_1, tensor__Constant_4_output_0, tensor__Constant_5_output_0, tensor__Constant_3_output_0, tensor__Constant_6_output_0, tu1.tensor__Slice_output_0);
	node__Constant_7( tensor__Constant_7_output_0);
	node__Add( tu1.tensor__Slice_output_0, tensor__Constant_7_output_0, tu2.tensor__Add_output_0);
	node__Constant_8( tensor__Constant_8_output_0);
	node__Reshape( tu2.tensor__Add_output_0, tensor__Constant_8_output_0, tu1.tensor__Reshape_output_0);
	node__Transpose_2( tensor_pf_features, tu2.tensor__Transpose_2_output_0);
	node__Constant_9( tensor__Constant_9_output_0);
	node__Reshape_1( tu2.tensor__Transpose_2_output_0, tensor__Constant_9_output_0, tu3.tensor__Reshape_1_output_0);
	node__Gather( tu3.tensor__Reshape_1_output_0, tu1.tensor__Reshape_output_0, tu2.tensor__Gather_output_0);
	node__Constant_10( tensor__Constant_10_output_0);
	node__Reshape_2( tu2.tensor__Gather_output_0, tensor__Constant_10_output_0, tu1.tensor__Reshape_2_output_0);
	node__Transpose_3( tu1.tensor__Reshape_2_output_0, tu2.tensor__Transpose_3_output_0);
	node__Constant_11( tensor__Constant_11_output_0);
	node__Unsqueeze( tensor_pf_features, tensor__Constant_11_output_0, tu1.tensor__Unsqueeze_output_0);
	node__Constant_12( tensor__Constant_12_output_0);
	node__Constant_13( tensor__Constant_13_output_0);
	node__ConstantOfShape( tensor__Constant_13_output_0, tu3.tensor__ConstantOfShape_output_0);
	node__Constant_14( &tensor__Constant_14_output_0);
	node__Mul_1( tu3.tensor__ConstantOfShape_output_0, &tensor__Constant_14_output_0, tu4.tensor__Mul_1_output_0);
	node__Equal( tensor__Constant_12_output_0, tu4.tensor__Mul_1_output_0, tu3.tensor__Equal_output_0);
	node__Expand( tu1.tensor__Unsqueeze_output_0, tensor__Where_output_0_static, tu3.tensor__Expand_output_0);
	node__Sub_2( tu2.tensor__Transpose_3_output_0, tu3.tensor__Expand_output_0, tu1.tensor__Sub_2_output_0);
	node__Concat( tu3.tensor__Expand_output_0, tu1.tensor__Sub_2_output_0, tu2.tensor__Concat_output_0);
	node__convs_0_Conv( tu2.tensor__Concat_output_0, tensor_onnx__Conv_103, tensor_onnx__Conv_104, tu1.tensor__convs_0_Conv_output_0);
	node__acts_0_Relu( tu1.tensor__convs_0_Conv_output_0, tu2.tensor__acts_0_Relu_output_0);
	node__Constant_15( tensor__Constant_15_output_0);
	node__ReduceMean( tu2.tensor__acts_0_Relu_output_0, tensor__Constant_15_output_0, tu1.tensor__ReduceMean_output_0);
	node__sc_Conv( tensor_pf_features, tensor_onnx__Conv_106, tu0.tensor_onnx__Conv_107, tu2.tensor__sc_Conv_output_0);
	node__Add_1( tu2.tensor__sc_Conv_output_0, tu1.tensor__ReduceMean_output_0, tu0.tensor__Add_1_output_0);
	node__sc_act_Relu( tu0.tensor__Add_1_output_0, tensor_output);
}
